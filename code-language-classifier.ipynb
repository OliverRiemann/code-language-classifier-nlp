{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Language Classifier with BiLSTM + Attention\n",
    "\n",
    "This project builds a deep learning model to classify code snippets into their corresponding programming languages. It uses a custom architecture combining an embedding layer, a bidirectional LSTM, and an attention mechanism to improve classification accuracy across 10 language classes.\n",
    "\n",
    "**Dataset**  \n",
    "The model is trained on a subset of [IBM Project CodeNet](https://developer.ibm.com/exchanges/data/all/project-codenet/), a large-scale dataset of source code files in multiple programming languages.\n",
    "\n",
    "**Model Objective**  \n",
    "To learn language-specific patterns in source code using a sequence model, enabling accurate prediction of the programming language for a given snippet.\n",
    "\n",
    "**Techniques Used**\n",
    "- Text preprocessing and tokenization of source code\n",
    "- Label encoding and padding of sequences\n",
    "- Neural network built with PyTorch\n",
    "- Evaluation using accuracy, F1-score, and classification report\n",
    "\n",
    "This notebook contains all steps: data preprocessing, model architecture, training loop, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "All code files are read line by line and stored as `(code_text, language_label)` pairs. The parser preserves line breaks and file structure. The language is extracted from the file extension (e.g., `.py`, `.c`, `.java`).\n",
    "\n",
    "We tokenize each code snippet using simple word/symbol-level tokenization, transforming the raw text into sequences suitable for neural network input.\n",
    "\n",
    "The processing pipeline includes:\n",
    "- Encoding language labels using `LabelEncoder`\n",
    "- Tokenizing code into vocabulary indices\n",
    "- Padding sequences to uniform length\n",
    "- Converting sequences and labels into PyTorch tensors\n",
    "- Creating a combined dataset and splitting into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code_files(folder_path):\n",
    "    file_paths = list(Path(folder_path).rglob(\"*.*\"))\n",
    "    data = []\n",
    "    for path in file_paths:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            content = f.read()\n",
    "            label = path.suffix[1:]  # 'py', 'c', etc.\n",
    "            data.append((content, label))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_code_files(\"data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then turn this list into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>#include&lt;stdio.h&gt;\\n\\n#define SET_MAX 1024\\n\\n/...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>(function(input) {\\n  var p = input.replace(/\\...</td>\n",
       "      <td>js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>#include &lt;bits/stdc++.h&gt;\\nusing namespace std;...</td>\n",
       "      <td>cpp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>using System;\\nusing System.IO;\\nusing System....</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>fn main(){\\n  loop {\\n    let nm: Vec&lt;usize&gt; =...</td>\n",
       "      <td>rs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  code label\n",
       "738  #include<stdio.h>\\n\\n#define SET_MAX 1024\\n\\n/...     c\n",
       "691  (function(input) {\\n  var p = input.replace(/\\...    js\n",
       "33   #include <bits/stdc++.h>\\nusing namespace std;...   cpp\n",
       "191  using System;\\nusing System.IO;\\nusing System....    cs\n",
       "317  fn main(){\\n  loop {\\n    let nm: Vec<usize> =...    rs"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df, columns=[\"code\", \"label\"])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "cpp     90\n",
       "py      90\n",
       "cs      90\n",
       "rs      90\n",
       "java    90\n",
       "hs      90\n",
       "php     90\n",
       "js      90\n",
       "c       90\n",
       "d       90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(code):\n",
    "    return re.findall(r'\\w+|[^\\s\\w]', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/',\n",
       " '/',\n",
       " 'template',\n",
       " '{',\n",
       " '{',\n",
       " '{',\n",
       " '#',\n",
       " 'include',\n",
       " '<',\n",
       " 'bits',\n",
       " '/',\n",
       " 'stdc',\n",
       " '+',\n",
       " '+',\n",
       " '.',\n",
       " 'h',\n",
       " '>',\n",
       " 'using',\n",
       " 'namespace',\n",
       " 'std',\n",
       " ';',\n",
       " '/',\n",
       " '/',\n",
       " '#',\n",
       " 'define',\n",
       " 'int',\n",
       " 'long',\n",
       " 'long',\n",
       " '#',\n",
       " 'define',\n",
       " 'GET_MACRO',\n",
       " '(',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ',',\n",
       " 'c',\n",
       " ',',\n",
       " 'd',\n",
       " ',',\n",
       " 'NAME',\n",
       " ',',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " ')',\n",
       " 'NAME',\n",
       " '#',\n",
       " 'define',\n",
       " 'REP2',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'n',\n",
       " ')',\n",
       " 'REP3',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " '0',\n",
       " ',',\n",
       " 'n',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'REP3',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ')',\n",
       " 'REP4',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ',',\n",
       " '1',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'REP4',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ',',\n",
       " 's',\n",
       " ')',\n",
       " 'for',\n",
       " '(',\n",
       " 'll',\n",
       " 'i',\n",
       " '=',\n",
       " '(',\n",
       " 'a',\n",
       " ')',\n",
       " ';',\n",
       " 'i',\n",
       " '<',\n",
       " '(',\n",
       " 'll',\n",
       " ')',\n",
       " '(',\n",
       " 'b',\n",
       " ')',\n",
       " ';',\n",
       " 'i',\n",
       " '+',\n",
       " '=',\n",
       " 's',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'RREP2',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'n',\n",
       " ')',\n",
       " 'RREP3',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " '0',\n",
       " ',',\n",
       " 'n',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'RREP3',\n",
       " '(',\n",
       " 'i',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'b',\n",
       " ')',\n",
       " 'for',\n",
       " '(',\n",
       " 'll',\n",
       " 'i',\n",
       " '=',\n",
       " '(',\n",
       " 'b',\n",
       " ')',\n",
       " '-',\n",
       " '1',\n",
       " ';',\n",
       " 'i',\n",
       " '>',\n",
       " '=',\n",
       " '(',\n",
       " 'll',\n",
       " ')',\n",
       " '(',\n",
       " 'a',\n",
       " ')',\n",
       " ';',\n",
       " 'i',\n",
       " '-',\n",
       " '-',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'rep',\n",
       " '(',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " ')',\n",
       " 'GET_MACRO',\n",
       " '(',\n",
       " '__VA_ARGS__',\n",
       " ',',\n",
       " 'REP4',\n",
       " ',',\n",
       " 'REP3',\n",
       " ',',\n",
       " 'REP2',\n",
       " ')',\n",
       " '(',\n",
       " '__VA_ARGS__',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'rrep',\n",
       " '(',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " ')',\n",
       " 'GET_MACRO',\n",
       " '(',\n",
       " '__VA_ARGS__',\n",
       " ',',\n",
       " ',',\n",
       " 'RREP3',\n",
       " ',',\n",
       " 'RREP2',\n",
       " ')',\n",
       " '(',\n",
       " '__VA_ARGS__',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'eb',\n",
       " 'emplace_back',\n",
       " '#',\n",
       " 'define',\n",
       " 'ef',\n",
       " 'emplace_front',\n",
       " '#',\n",
       " 'define',\n",
       " 'pb',\n",
       " 'pop_back',\n",
       " '#',\n",
       " 'define',\n",
       " 'pf',\n",
       " 'pop_front',\n",
       " '#',\n",
       " 'define',\n",
       " 'all',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " 'begin',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ',',\n",
       " 'end',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " '#',\n",
       " 'define',\n",
       " 'mp',\n",
       " 'make_pair',\n",
       " '#',\n",
       " 'define',\n",
       " 'mt',\n",
       " 'make_tuple',\n",
       " '#',\n",
       " 'define',\n",
       " 'fi',\n",
       " 'first',\n",
       " '#',\n",
       " 'define',\n",
       " 'se',\n",
       " 'second',\n",
       " '#',\n",
       " 'define',\n",
       " 'popcnt',\n",
       " '__builtin_popcountll',\n",
       " '#',\n",
       " 'ifdef',\n",
       " 'DEBUG',\n",
       " '#',\n",
       " 'define',\n",
       " 'dump',\n",
       " '(',\n",
       " 'x',\n",
       " ')',\n",
       " 'cerr',\n",
       " '<',\n",
       " '<',\n",
       " '#',\n",
       " 'x',\n",
       " '\"',\n",
       " '=',\n",
       " '\"',\n",
       " '<',\n",
       " '<',\n",
       " 'x',\n",
       " '<',\n",
       " '<',\n",
       " 'endl',\n",
       " ';',\n",
       " '#',\n",
       " 'else',\n",
       " '#',\n",
       " 'define',\n",
       " 'dump',\n",
       " '(',\n",
       " 'x',\n",
       " ')',\n",
       " '#',\n",
       " 'endif',\n",
       " 'using',\n",
       " 'uint',\n",
       " '=',\n",
       " 'unsigned',\n",
       " ';',\n",
       " 'using',\n",
       " 'll',\n",
       " '=',\n",
       " 'long',\n",
       " 'long',\n",
       " ';',\n",
       " 'using',\n",
       " 'ull',\n",
       " '=',\n",
       " 'unsigned',\n",
       " 'long',\n",
       " 'long',\n",
       " ';',\n",
       " 'using',\n",
       " 'ld',\n",
       " '=',\n",
       " 'long',\n",
       " 'double',\n",
       " ';',\n",
       " 'using',\n",
       " 'vi',\n",
       " '=',\n",
       " 'vector',\n",
       " '<',\n",
       " 'int',\n",
       " '>',\n",
       " ';',\n",
       " 'using',\n",
       " 'vvi',\n",
       " '=',\n",
       " 'vector',\n",
       " '<',\n",
       " 'vi',\n",
       " '>',\n",
       " ';',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'using',\n",
       " 'maxheap',\n",
       " '=',\n",
       " 'priority_queue',\n",
       " '<',\n",
       " 'T',\n",
       " ',',\n",
       " 'vector',\n",
       " '<',\n",
       " 'T',\n",
       " '>',\n",
       " ',',\n",
       " 'less',\n",
       " '<',\n",
       " 'T',\n",
       " '>',\n",
       " '>',\n",
       " ';',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'using',\n",
       " 'minheap',\n",
       " '=',\n",
       " 'priority_queue',\n",
       " '<',\n",
       " 'T',\n",
       " ',',\n",
       " 'vector',\n",
       " '<',\n",
       " 'T',\n",
       " '>',\n",
       " ',',\n",
       " 'greater',\n",
       " '<',\n",
       " 'T',\n",
       " '>',\n",
       " '>',\n",
       " ';',\n",
       " 'const',\n",
       " 'int',\n",
       " 'INF',\n",
       " '=',\n",
       " '1e9',\n",
       " '+',\n",
       " '10',\n",
       " ';',\n",
       " 'const',\n",
       " 'll',\n",
       " 'LLINF',\n",
       " '=',\n",
       " '1e18',\n",
       " '+',\n",
       " '10',\n",
       " ';',\n",
       " 'const',\n",
       " 'int',\n",
       " 'dx',\n",
       " '[',\n",
       " ']',\n",
       " '=',\n",
       " '{',\n",
       " '-',\n",
       " '1',\n",
       " ',',\n",
       " '0',\n",
       " ',',\n",
       " '1',\n",
       " ',',\n",
       " '0',\n",
       " ',',\n",
       " '-',\n",
       " '1',\n",
       " ',',\n",
       " '1',\n",
       " ',',\n",
       " '1',\n",
       " ',',\n",
       " '-',\n",
       " '1',\n",
       " '}',\n",
       " ';',\n",
       " 'const',\n",
       " 'int',\n",
       " 'dy',\n",
       " '[',\n",
       " ']',\n",
       " '=',\n",
       " '{',\n",
       " '0',\n",
       " ',',\n",
       " '-',\n",
       " '1',\n",
       " ',',\n",
       " '0',\n",
       " ',',\n",
       " '1',\n",
       " ',',\n",
       " '-',\n",
       " '1',\n",
       " ',',\n",
       " '-',\n",
       " '1',\n",
       " ',',\n",
       " '1',\n",
       " ',',\n",
       " '1',\n",
       " '}',\n",
       " ';',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " 'sq',\n",
       " '(',\n",
       " 'T',\n",
       " 'x',\n",
       " ')',\n",
       " '{',\n",
       " 'return',\n",
       " 'x',\n",
       " '*',\n",
       " 'x',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " ',',\n",
       " 'typename',\n",
       " 'U',\n",
       " '>',\n",
       " 'inline',\n",
       " 'bool',\n",
       " 'chmax',\n",
       " '(',\n",
       " 'T',\n",
       " '&',\n",
       " 'x',\n",
       " ',',\n",
       " 'U',\n",
       " 'y',\n",
       " ')',\n",
       " '{',\n",
       " 'if',\n",
       " '(',\n",
       " 'x',\n",
       " '>',\n",
       " '=',\n",
       " 'y',\n",
       " ')',\n",
       " 'return',\n",
       " 'false',\n",
       " ';',\n",
       " 'x',\n",
       " '=',\n",
       " 'y',\n",
       " ';',\n",
       " 'return',\n",
       " 'true',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " ',',\n",
       " 'typename',\n",
       " 'U',\n",
       " '>',\n",
       " 'inline',\n",
       " 'bool',\n",
       " 'chmin',\n",
       " '(',\n",
       " 'T',\n",
       " '&',\n",
       " 'x',\n",
       " ',',\n",
       " 'U',\n",
       " 'y',\n",
       " ')',\n",
       " '{',\n",
       " 'if',\n",
       " '(',\n",
       " 'x',\n",
       " '<',\n",
       " '=',\n",
       " 'y',\n",
       " ')',\n",
       " 'return',\n",
       " 'false',\n",
       " ';',\n",
       " 'x',\n",
       " '=',\n",
       " 'y',\n",
       " ';',\n",
       " 'return',\n",
       " 'true',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " '&',\n",
       " 'sort',\n",
       " '(',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'sort',\n",
       " '(',\n",
       " 'all',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 'c',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " '&',\n",
       " 'reverse',\n",
       " '(',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'reverse',\n",
       " '(',\n",
       " 'all',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 'c',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " '&',\n",
       " 'unique',\n",
       " '(',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'sort',\n",
       " '(',\n",
       " 'all',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " 'c',\n",
       " '.',\n",
       " 'erase',\n",
       " '(',\n",
       " 'unique',\n",
       " '(',\n",
       " 'all',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ')',\n",
       " ',',\n",
       " 'end',\n",
       " '(',\n",
       " 'c',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 'c',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " 'sorted',\n",
       " '(',\n",
       " 'const',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'T',\n",
       " 'd',\n",
       " '=',\n",
       " 'c',\n",
       " ';',\n",
       " 'return',\n",
       " 'move',\n",
       " '(',\n",
       " 'sort',\n",
       " '(',\n",
       " 'd',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " 'reversed',\n",
       " '(',\n",
       " 'const',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'T',\n",
       " 'd',\n",
       " '=',\n",
       " 'c',\n",
       " ';',\n",
       " 'return',\n",
       " 'move',\n",
       " '(',\n",
       " 'reverse',\n",
       " '(',\n",
       " 'd',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " '>',\n",
       " 'inline',\n",
       " 'T',\n",
       " 'uniqued',\n",
       " '(',\n",
       " 'const',\n",
       " 'T',\n",
       " '&',\n",
       " 'c',\n",
       " ')',\n",
       " '{',\n",
       " 'T',\n",
       " 'd',\n",
       " '=',\n",
       " 'c',\n",
       " ';',\n",
       " 'return',\n",
       " 'move',\n",
       " '(',\n",
       " 'unique',\n",
       " '(',\n",
       " 'd',\n",
       " ')',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'll',\n",
       " 'modpow',\n",
       " '(',\n",
       " 'll',\n",
       " 'x',\n",
       " ',',\n",
       " 'll',\n",
       " 'e',\n",
       " ',',\n",
       " 'll',\n",
       " 'mod',\n",
       " '=',\n",
       " '1000000007',\n",
       " ')',\n",
       " '{',\n",
       " 'll',\n",
       " 'res',\n",
       " '=',\n",
       " '1',\n",
       " ';',\n",
       " 'e',\n",
       " '%',\n",
       " '=',\n",
       " 'mod',\n",
       " '-',\n",
       " '1',\n",
       " ';',\n",
       " 'while',\n",
       " '(',\n",
       " 'e',\n",
       " ')',\n",
       " '{',\n",
       " 'if',\n",
       " '(',\n",
       " 'e',\n",
       " '&',\n",
       " '1',\n",
       " ')',\n",
       " 'res',\n",
       " '=',\n",
       " 'res',\n",
       " '*',\n",
       " 'x',\n",
       " ';',\n",
       " 'x',\n",
       " '=',\n",
       " 'x',\n",
       " '*',\n",
       " 'x',\n",
       " ';',\n",
       " 'e',\n",
       " '>',\n",
       " '>',\n",
       " '=',\n",
       " '1',\n",
       " ';',\n",
       " '}',\n",
       " 'return',\n",
       " 'res',\n",
       " ';',\n",
       " '}',\n",
       " 'inline',\n",
       " 'll',\n",
       " 'in',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " 'll',\n",
       " 'x',\n",
       " ';',\n",
       " 'scanf',\n",
       " '(',\n",
       " '\"',\n",
       " '%',\n",
       " 'lld',\n",
       " '\"',\n",
       " ',',\n",
       " '&',\n",
       " 'x',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 'x',\n",
       " ';',\n",
       " '}',\n",
       " 'inline',\n",
       " 'double',\n",
       " 'inD',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " 'double',\n",
       " 'x',\n",
       " ';',\n",
       " 'scanf',\n",
       " '(',\n",
       " '\"',\n",
       " '%',\n",
       " 'lf',\n",
       " '\"',\n",
       " ',',\n",
       " '&',\n",
       " 'x',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 'x',\n",
       " ';',\n",
       " '}',\n",
       " 'inline',\n",
       " 'string',\n",
       " 'inS',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " 'static',\n",
       " 'char',\n",
       " 's',\n",
       " '[',\n",
       " '1',\n",
       " '<',\n",
       " '<',\n",
       " '20',\n",
       " ']',\n",
       " ';',\n",
       " 'scanf',\n",
       " '(',\n",
       " '\"',\n",
       " '%',\n",
       " 's',\n",
       " '\"',\n",
       " ',',\n",
       " 's',\n",
       " ')',\n",
       " ';',\n",
       " 'return',\n",
       " 's',\n",
       " ';',\n",
       " '}',\n",
       " 'pair',\n",
       " '<',\n",
       " 'll',\n",
       " ',',\n",
       " 'll',\n",
       " '>',\n",
       " 'rot45',\n",
       " '(',\n",
       " 'll',\n",
       " 'x',\n",
       " ',',\n",
       " 'll',\n",
       " 'y',\n",
       " ')',\n",
       " '{',\n",
       " 'return',\n",
       " 'mp',\n",
       " '(',\n",
       " 'x',\n",
       " '+',\n",
       " 'y',\n",
       " ',',\n",
       " 'x',\n",
       " '-',\n",
       " 'y',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'pair',\n",
       " '<',\n",
       " 'll',\n",
       " ',',\n",
       " 'll',\n",
       " '>',\n",
       " 'rot45inv',\n",
       " '(',\n",
       " 'll',\n",
       " 'u',\n",
       " ',',\n",
       " 'll',\n",
       " 'v',\n",
       " ')',\n",
       " '{',\n",
       " 'return',\n",
       " 'mp',\n",
       " '(',\n",
       " '(',\n",
       " 'u',\n",
       " '+',\n",
       " 'v',\n",
       " ')',\n",
       " '/',\n",
       " '2',\n",
       " ',',\n",
       " '(',\n",
       " 'u',\n",
       " '-',\n",
       " 'v',\n",
       " ')',\n",
       " '/',\n",
       " '2',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'template',\n",
       " '<',\n",
       " 'typename',\n",
       " 'T',\n",
       " ',',\n",
       " 'size_t',\n",
       " 'N',\n",
       " '>',\n",
       " 'struct',\n",
       " 'print_tuple',\n",
       " '{',\n",
       " 'static',\n",
       " 'void',\n",
       " 'print',\n",
       " '(',\n",
       " 'const',\n",
       " 'T',\n",
       " '&',\n",
       " 't',\n",
       " ',',\n",
       " 'ostream',\n",
       " '&',\n",
       " 'os',\n",
       " ')',\n",
       " '{',\n",
       " 'print_tuple',\n",
       " '<',\n",
       " 'T',\n",
       " ',',\n",
       " 'N',\n",
       " '-',\n",
       " '1',\n",
       " '>',\n",
       " ':',\n",
       " ':',\n",
       " 'print',\n",
       " '(',\n",
       " 't',\n",
       " ',',\n",
       " 'os',\n",
       " ')',\n",
       " ';',\n",
       " 'os',\n",
       " '<',\n",
       " '<',\n",
       " '\"',\n",
       " '\"',\n",
       " '<',\n",
       " '<',\n",
       " 'get',\n",
       " '<',\n",
       " 'N',\n",
       " '-',\n",
       " '1',\n",
       " '>',\n",
       " '(',\n",
       " 't',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " '}',\n",
       " ';',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df[\"code\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a vocabulary based on the training data, mapping each unique token to an integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for code in df['code']:\n",
    "    tokens = tokenize(code)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# Vocabulary creation\n",
    "token_freqs = Counter(all_tokens)\n",
    "vocab = {token: i+2 for i, (token, _) in enumerate(token_freqs.items())}\n",
    "vocab[\"<PAD>\"] = 0\n",
    "vocab[\"<UNK>\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the tokens in each code snippet to their corresponding indices in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_ids(tokens, vocab):\n",
    "    return [vocab.get(t, vocab[\"<UNK>\"]) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 500])\n",
      "torch.Size([900])\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "MAX_LEN = 500\n",
    "encoded_sequences = []\n",
    "\n",
    "for code in df[\"code\"]:\n",
    "    tokens = tokenize(code)\n",
    "    token_ids = tokens_to_ids(tokens[:MAX_LEN], vocab)\n",
    "    encoded_sequences.append(torch.tensor(token_ids, dtype=torch.long))\n",
    "\n",
    "padded_sequences = pad_sequence(encoded_sequences, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "labels_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "print(padded_sequences.shape)  # (num_samples, MAX_LEN)\n",
    "print(labels_tensor.shape)     # (num_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    2,    3,  ...,  105,  113,   17],\n",
       "        [   5,    6,    7,  ...,   13,  231,   17],\n",
       "        [   5,    6,    7,  ...,   13,  231,   17],\n",
       "        ...,\n",
       "        [ 709,   16,   11,  ..., 6300,   17, 6539],\n",
       "        [ 709,   16,   11,  ...,   40,  393,   99],\n",
       "        [ 709,   16,   11,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(padded_sequences, labels_tensor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "The neural network follows a deep learning pipeline optimized for sequential classification:\n",
    "\n",
    "- **Embedding Layer**: Transforms token IDs into dense vector representations\n",
    "- **Bidirectional LSTM**: Captures context from both forward and backward directions\n",
    "- **Attention Layer**: Assigns dynamic weights to sequence elements to emphasize informative tokens\n",
    "- **Fully Connected Output Layer**: Maps the attention-aggregated features to class probabilities via softmax\n",
    "\n",
    "The model is trained using Cross-Entropy Loss and the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeClassifierBiLSTM_Attn(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attn = nn.Linear(hidden_dim * 2, 1)  # Attention layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)                           # (B, T, E)\n",
    "        out, _ = self.lstm(x)                           # (B, T, 2H)\n",
    "        attn_weights = torch.softmax(self.attn(out), dim=1)  # (B, T, 1)\n",
    "        context = torch.sum(attn_weights * out, dim=1)  # (B, 2H),\n",
    "        context = self.dropout(context)\n",
    "        return self.fc(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CodeClassifierBiLSTM_Attn(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_classes=len(label_encoder.classes_),\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=10, save_path=\"best_model.pt\"):\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)  # logits\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # === VALIDATION ===\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.numpy())\n",
    "\n",
    "        acc = accuracy_score(val_labels, val_preds)\n",
    "        f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_loss:.4f} | Val Acc: {acc:.4f} | Val F1: {f1:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Nuevo mejor modelo guardado con F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_report(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.90      1.00      0.95        18\n",
      "         cpp       1.00      1.00      1.00        10\n",
      "          cs       1.00      1.00      1.00        18\n",
      "           d       1.00      1.00      1.00        21\n",
      "          hs       1.00      0.96      0.98        24\n",
      "        java       1.00      0.96      0.98        24\n",
      "          js       1.00      0.95      0.98        22\n",
      "         php       1.00      1.00      1.00        13\n",
      "          py       1.00      1.00      1.00        11\n",
      "          rs       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.98       180\n",
      "   macro avg       0.98      0.99      0.99       180\n",
      "weighted avg       0.98      0.98      0.98       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train_model(model, train_loader, val_loader, epochs=50)\n",
    "final_report(model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "The test set undergoes the same preprocessing steps: tokenization, index conversion, and padding — using the trained vocabulary and label encoder.\n",
    "\n",
    "Evaluation metrics include:\n",
    "- **Accuracy**\n",
    "- **F1-Score (per class and macro-average)**\n",
    "- **Confusion matrix**\n",
    "\n",
    "### Key Results:\n",
    "- 7 out of 10 languages were classified with **F1 = 1.00**\n",
    "- Minor confusion occurred between languages with overlapping syntax (e.g., Python and JavaScript)\n",
    "- No classes exhibited consistently poor performance\n",
    "\n",
    "The model demonstrates high robustness and a strong ability to distinguish syntactic patterns across multiple programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = read_code_files(\"data/test\")\n",
    "df_test = pd.DataFrame(df_test, columns=[\"code\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "cpp     10\n",
       "py      10\n",
       "cs      10\n",
       "rs      10\n",
       "java    10\n",
       "hs      10\n",
       "php     10\n",
       "js      10\n",
       "c       10\n",
       "d       10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test =  df_test[df_test[\"label\"] != \"\"]\n",
    "\n",
    "df_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = label_encoder.transform(df_test[\"label\"])\n",
    "\n",
    "# Tokenize and turn into IDs\n",
    "encoded_test_sequences = []\n",
    "for code in df_test[\"code\"]:\n",
    "    tokens = tokenize(code)\n",
    "    token_ids = tokens_to_ids(tokens[:MAX_LEN], vocab)\n",
    "    encoded_test_sequences.append(torch.tensor(token_ids, dtype=torch.long))\n",
    "\n",
    "# Padding\n",
    "padded_test = pad_sequence(encoded_test_sequences, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "labels_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(padded_test, labels_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, y in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            batch_preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            preds.extend(batch_preds)\n",
    "            labels.extend(y.numpy())\n",
    "            \n",
    "    print(classification_report(labels, preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       1.00      1.00      1.00        10\n",
      "         cpp       1.00      1.00      1.00        10\n",
      "          cs       1.00      1.00      1.00        10\n",
      "           d       1.00      1.00      1.00        10\n",
      "          hs       1.00      0.90      0.95        10\n",
      "        java       1.00      1.00      1.00        10\n",
      "          js       0.91      1.00      0.95        10\n",
      "         php       1.00      1.00      1.00        10\n",
      "          py       0.91      1.00      0.95        10\n",
      "          rs       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.98      0.98      0.98       100\n",
      "weighted avg       0.98      0.98      0.98       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.to(device)\n",
    "evaluate_on_test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(code_str, vocab, max_len=500):\n",
    "    tokens = tokenize(code_str)\n",
    "    token_ids = tokens_to_ids(tokens[:max_len], vocab)\n",
    "    seq = torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "    if len(seq) < max_len:\n",
    "        pad_len = max_len - len(seq)\n",
    "        pad_tensor = torch.full((pad_len,), vocab[\"<PAD>\"], dtype=torch.long)\n",
    "        seq = torch.cat([seq, pad_tensor])\n",
    "    return seq.unsqueeze(0)  # shape: (1, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language(code_str, model, vocab, label_encoder, max_len=500):\n",
    "    model.eval()\n",
    "    input_tensor = prepare_input(code_str, vocab, max_len).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)\n",
    "        pred_idx = torch.argmax(logits, dim=1).item()\n",
    "        pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "        return pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Demo\n",
    "\n",
    "Below is an example of the model predicting the programming language of unseen code snippets.\n",
    "\n",
    "The classifier accurately detects the correct language even on short or ambiguous samples by leveraging both sequential context (via BiLSTM) and learned attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Código (primeras 10 líneas):\n",
      "import std.stdio, std.string, std.conv;\n",
      "import std.array, std.algorithm, std.range;\n",
      "\n",
      "void main()\n",
      "{\n",
      "    foreach(s;stdin.byLine())\n",
      "    {\n",
      "        int[10] c; foreach(n;s) ++c[n-'0'];\n",
      "        bool dfs(int n, bool d)\n",
      "        {\n",
      "Predicted value: d, Actual value: d\n"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, len(df_test))\n",
    "sample_code = df_test[\"code\"].iloc[rand_int]  # Change this to test other samples\n",
    "print(f\" Código (primeras 10 líneas):\\n{'\\n'.join(sample_code.splitlines()[:10])}\")\n",
    "predicted_language = predict_language(sample_code, model, vocab, label_encoder, max_len=MAX_LEN)\n",
    "print(f\"Predicted value: {predicted_language}, Actual value: {df_test[\"label\"].iloc[rand_int]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
